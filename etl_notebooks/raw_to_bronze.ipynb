{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d39be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Bronze\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c1e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251797b",
   "metadata": {},
   "source": [
    "### Trip Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ad897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_type = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"inferSchema\", \"true\")\\\n",
    "                            .load(r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_raw\\trip_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eef339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_type.write.format(\"delta\")\\\n",
    "                    .mode(\"overwrite\")\\\n",
    "                    .option(\"path\",r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_bronze\\trip_type\")\\\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213dcbb",
   "metadata": {},
   "source": [
    "### Trip Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_zone = spark.read.format(\"csv\")\\\n",
    "                               .option(\"header\",\"true\")\\\n",
    "                               .option(\"inferSchema\",\"true\")\\\n",
    "                               .load(r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_raw\\trip_zone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a630656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_zone.write.format(\"delta\")\\\n",
    "                    .mode(\"overwrite\")\\\n",
    "                    .option(\"path\",r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_bronze\\trip_zone\")\\\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35629c7",
   "metadata": {},
   "source": [
    "### Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a949e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType().fromDDL(\"\"\"\n",
    "    VendorID BIGINT,\n",
    "    lpep_pickup_datetime TIMESTAMP,\n",
    "    lpep_dropoff_datetime TIMESTAMP,\n",
    "    store_and_fwd_flag STRING,\n",
    "    RatecodeID BIGINT,\n",
    "    PULocationID BIGINT,\n",
    "    DOLocationID BIGINT,\n",
    "    passenger_count BIGINT,\n",
    "    trip_distance DOUBLE,\n",
    "    fare_amount DOUBLE,\n",
    "    extra DOUBLE,\n",
    "    mta_tax DOUBLE,\n",
    "    tip_amount DOUBLE,\n",
    "    tolls_amount DOUBLE,\n",
    "    ehail_fee DOUBLE,\n",
    "    improvement_surcharge DOUBLE,\n",
    "    total_amount DOUBLE,\n",
    "    payment_type BIGINT,\n",
    "    trip_type BIGINT,\n",
    "    congestion_surcharge DOUBLE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "raw_path = r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_raw\\trip_data\"\n",
    "\n",
    "for file in os.listdir(raw_path):\n",
    "\n",
    "    full_path = os.path.join(raw_path, file)\n",
    "\n",
    "    df_trip_data = spark.read.parquet(full_path)\n",
    "\n",
    "    # Cast every column according to target schema\n",
    "    for field in mySchema.fields:\n",
    "        df_trip_data = df_trip_data.withColumn(field.name, col(field.name).cast(field.dataType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99011970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_trip_data.write.format(\"delta\")\\\n",
    "                  .mode(\"overwrite\")\\\n",
    "                  .option(\"path\",r\"C:\\Users\\gauth\\Desktop\\Extended Medallion Architecture\\storage_bronze\\trip_data\")\\\n",
    "                  .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
